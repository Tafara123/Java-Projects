import csv
import os
import re
import shutil
import glob
import base64
import markdown
from langchain.text_splitter import RecursiveCharacterTextSplitter
import tempfile
from typing import Text, Optional
from markdown_pdf import MarkdownPdf, Section
import datetime


def escape_invalid_chars(s):
    return re.sub(r'[\x00-\x1F\x7F-\x9F]', lambda m: '\\u{:04x}'.format(ord(m.group(0))), s)


def create_csv(name, column_names, result):
    # Open csv file for writing
    with open(f'./input/{name}.csv', mode='w', encoding='utf-8', newline='') as csv_file:
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(column_names)
        csv_writer.writerows(result)


def read_first_lines_from_file(name):
    file_path = "./input/" + name
    with open(file_path, 'r') as file:
        reader = csv.reader(file)
        lines = [next(reader) for _ in range(2)]
    return lines


def delete_all_files_in_directory(directory_path):
    if os.path.exists(directory_path):
        for file_name in os.listdir(directory_path):
            file_path = os.path.join(directory_path, file_name)
            if os.path.isfile(file_path):
                os.remove(file_path)


def save_uploaded_file(uploaded_file, directory_path):
    delete_all_files_in_directory(directory_path)
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
    file_path = os.path.join(directory_path, uploaded_file.name)
    with open(file_path, 'wb') as f:
        shutil.copyfileobj(uploaded_file, f)
    return file_path


def read_files(directory_path):
    file_contents = {}
    for file_path in glob.glob(os.path.join(directory_path, '*')):
        with open(file_path, 'r') as file:
            content = file.read()
            file_name = os.path.basename(file_path)
            file_contents[file_name] = content
    return file_contents


def read_file(file_path):
    with open(file_path, 'r') as file:
        content = file.read()
    return content


def find_file(file_name):
    """
    Enhanced file finder that attempts to locate a file by name in the input directory
    using multiple search strategies.
    
    Args:
        file_name: Name of the file to find
        
    Returns:
        str or None: Path to the found file or None if not found
    """
    # Search in the standard path first
    for root, dirs, files in os.walk('./input/BF4000M1/'):
        if file_name in files:
            return os.path.join(root, file_name)
            
    # Try alternative locations if not found
    alternative_paths = [
        './input/',  # Root input directory
        './input/uploaded/',  # Uploaded files directory
        './',  # Current directory
    ]
    
    for base_path in alternative_paths:
        if os.path.exists(base_path):
            for root, dirs, files in os.walk(base_path):
                # Try exact match
                if file_name in files:
                    return os.path.join(root, file_name)
                
                # Try case-insensitive match
                for f in files:
                    if f.upper() == file_name.upper():
                        return os.path.join(root, f)
    
    # Not found            
    return None


def save_as_markdown(input_text, file_path):
    """Save text as a markdown file, ensuring the directory exists"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as file:
        file.write(input_text)


# Function to convert image to base64 string
def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()


def node_exists(node_id, st):
    for node in st.session_state['nodes']:
        if node.id == node_id:
            return True
    return False


def file_splitter(file_path):
    """
    Split a COBOL file into manageable chunks for processing.
    
    Args:
        file_path: Path to the COBOL program file
        
    Returns:
        list: List of text chunks
    """
    # Define custom splitter with File-specific break points
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=4000,
        chunk_overlap=200
    )

    # Read Code-File to chunk with error handling
    try:
        with open(file_path, "r", encoding='utf-8') as file:
            pgm_code = file.read()
    except UnicodeDecodeError:
        # Try with a different encoding if UTF-8 fails
        with open(file_path, "r", encoding='latin-1', errors='replace') as file:
            pgm_code = file.read()

    # Apply splitter to create chunks
    return text_splitter.split_text(pgm_code)


def intelligent_file_splitter(file_path, max_chunk_size=15000, min_chunk_size=5000):
    """
    Advanced file splitter that attempts to split COBOL code more intelligently
    by respecting procedure and division boundaries where possible.
    
    Args:
        file_path: Path to the COBOL program file
        max_chunk_size: Maximum size of a chunk in characters
        min_chunk_size: Minimum size of a chunk in characters
        
    Returns:
        list: List of text chunks that follow COBOL structural boundaries
    """
    # Read the file with error handling
    try:
        with open(file_path, "r", encoding='utf-8') as file:
            file_content = file.read()
    except UnicodeDecodeError:
        # Try with a different encoding if UTF-8 fails
        with open(file_path, "r", encoding='latin-1', errors='replace') as file:
            file_content = file.read()
    
    # Define COBOL structural markers to split on
    division_markers = [
        "IDENTIFICATION DIVISION",
        "ENVIRONMENT DIVISION",
        "DATA DIVISION",
        "PROCEDURE DIVISION"
    ]
    
    section_markers = [
        "CONFIGURATION SECTION",
        "INPUT-OUTPUT SECTION",
        "FILE SECTION",
        "WORKING-STORAGE SECTION",
        "LINKAGE SECTION"
    ]
    
    # Compile patterns for divisions and sections
    division_pattern = r'(?i)(\s+|^)(' + '|'.join(division_markers) + r')(\s+|\.)'
    section_pattern = r'(?i)(\s+|^)(' + '|'.join(section_markers) + r')(\s+|\.)'
    
    # Find all division and section boundaries
    division_matches = list(re.finditer(division_pattern, file_content))
    section_matches = list(re.finditer(section_pattern, file_content))
    
    # Combine all potential split points and sort by position
    split_points = []
    
    # Add division boundaries (highest priority)
    for match in division_matches:
        split_points.append((match.start(), 3))  # Higher priority
    
    # Add section boundaries (medium priority)
    for match in section_matches:
        split_points.append((match.start(), 2))  # Medium priority
    
    # Add paragraph boundaries (lowest priority)
    paragraph_pattern = r'(?i)(\n\s+\S+\s+SECTION\s*\.|\n\s+\d+\-\S+\s*\.)'
    for match in re.finditer(paragraph_pattern, file_content):
        split_points.append((match.start(), 1))  # Lower priority
    
    # Sort split points by position
    split_points.sort(key=lambda x: x[0])
    
    # If file is small enough, return it as a single chunk
    if len(file_content) <= max_chunk_size:
        return [file_content]
    
    # Create chunks based on split points
    chunks = []
    start_pos = 0
    
    # Build chunks
    for i, (pos, priority) in enumerate(split_points):
        # Check if we need to split
        if pos - start_pos >= max_chunk_size:
            # Find the best split point before the max_chunk_size limit
            best_split_pos = start_pos
            best_priority = 0
            
            for split_pos, split_priority in split_points:
                if start_pos < split_pos < start_pos + max_chunk_size:
                    if split_priority > best_priority or best_split_pos == start_pos:
                        best_split_pos = split_pos
                        best_priority = split_priority
            
            # If no good split point found, just use max_chunk_size
            if best_split_pos == start_pos:
                chunks.append(file_content[start_pos:start_pos + max_chunk_size])
                start_pos += max_chunk_size
            else:
                chunks.append(file_content[start_pos:best_split_pos])
                start_pos = best_split_pos
    
    # Add the final chunk
    if start_pos < len(file_content):
        chunks.append(file_content[start_pos:])
    
    # Ensure minimum context by adding overlaps
    final_chunks = []
    for i, chunk in enumerate(chunks):
        # Add beginning context from previous chunk if available
        if i > 0 and len(chunks[i-1]) > 0:
            overlap_size = min(1000, len(chunks[i-1]))
            final_chunks.append(chunks[i-1][-overlap_size:] + chunk)
        else:
            final_chunks.append(chunk)
    
    return final_chunks


def markdown_to_pdf(output_file: Text, markdown_content: Optional[Text] = None, file_path: Optional[Text] = None):
    """
    Basic markdown to PDF conversion using the markdown_pdf library.
    
    Args:
        output_file: Path to save the PDF file
        markdown_content: Markdown content to convert (optional)
        file_path: Path to a markdown file to convert (optional)
    """
    if markdown_content is None and file_path is None:
        raise ValueError("Either markdown_content or file_path must be provided.")

    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    try:
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.md') as temp_file:
            if markdown_content is not None:
                temp_file.write(markdown_content)
            elif file_path is not None:
                with open(file_path, 'r') as f:
                    markdown_content = f.read()
                    temp_file.write(markdown_content)

            pdf = MarkdownPdf()
            pdf.meta["title"] = 'COBOL Program Documentation'
            pdf.add_section(Section(markdown_content, toc=False))
            pdf.save(output_file)
            
        return True
    except Exception as e:
        print(f"Error generating PDF: {e}")
        
        # Fallback: save as plain text with .pdf extension
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content or '')
            
        return False


def generate_enhanced_pdf(markdown_content: Text, output_file: Text, program_name: Text = None):
    """
    Enhanced PDF generation with better styling, table of contents, and metadata.
    
    Args:
        markdown_content: Markdown content to convert to PDF
        output_file: Path where the PDF will be saved
        program_name: Name of the COBOL program (for metadata)
        
    Returns:
        bool: Success or failure of PDF generation
    """
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    # First try to use the markdown_pdf library with enhanced features
    try:
        # Build metadata
        metadata = {
            "title": f"Documentation: {program_name or 'COBOL Program'}",
            "author": "COBOL Documentation Generator",
            "date": datetime.datetime.now().strftime("%Y-%m-%d"),
            "subject": "Program Documentation"
        }
        
        # Add a table of contents (extract headings from markdown)
        toc_items = re.findall(r'^##?\s+(.*?)$', markdown_content, re.MULTILINE)
        toc_md = "# Table of Contents\n\n"
        for item in toc_items:
            toc_md += f"- {item}\n"
        
        # Combine TOC with content
        full_content = f"{toc_md}\n\n---\n\n{markdown_content}"
        
        # Generate PDF with enhanced styling
        pdf = MarkdownPdf()
        
        # Set metadata
        for key, value in metadata.items():
            pdf.meta[key] = value
        
        # Add cover page
        cover_content = f"""
        # {metadata['title']}
        
        **Generated by**: {metadata['author']}
        
        **Date**: {metadata['date']}
        """
        
        pdf.add_section(Section(cover_content, toc=False))
        pdf.add_section(Section(full_content, toc=True))
        
        pdf.save(output_file)
        return True
        
    except Exception as e:
        print(f"Error with enhanced PDF generation: {e}")
        
        # Fall back to basic PDF generation
        try:
            return markdown_to_pdf(output_file, markdown_content)
        except Exception as e2:
            print(f"Error with fallback PDF generation: {e2}")
            
            # Last resort: save as HTML
            html_output = output_file.replace('.pdf', '.html')
            html_content = markdown.markdown(markdown_content)
            
            # Add basic styling
            styled_html = f"""<!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <title>{program_name or 'COBOL Program'} Documentation</title>
                <style>
                    body {{ font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; }}
                    h1, h2, h3 {{ color: #2c3e50; }}
                    pre {{ background-color: #f5f5f5; padding: 10px; border-radius: 5px; }}
                </style>
            </head>
            <body>
                <h1>{program_name or 'COBOL Program'} Documentation</h1>
                {html_content}
            </body>
            </html>"""
            
            with open(html_output, 'w', encoding='utf-8') as f:
                f.write(styled_html)
                
            # Save plain text as PDF
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
                
            print(f"Generated HTML alternative: {html_output}")
            return False
